---
- name: "{{ hadoop_task_prefix }} Create hadoop group"
  ansible.builtin.group:
    name: "{{ hadoop_group }}"
    state: present

- name: "{{ hadoop_task_prefix }} Create hadoop user"
  ansible.builtin.user:
    name: "{{ hadoop_user }}"
    shell: "{{ hadoop_user_shell }}"
    group: "{{ hadoop_group }}"
    state: present

- name: "{{ hadoop_task_prefix }} Create yarn group"
  ansible.builtin.group:
    name: "{{ yarn_group }}"
    state: present

- name: "{{ hadoop_task_prefix }} Create yarn user"
  ansible.builtin.user:
    name: "{{ yarn_user }}"
    shell: "{{ yarn_user_shell }}"
    group: "{{ yarn_group }}"
    state: present

- name: "{{ hadoop_task_prefix }} Download checksum"
  ansible.builtin.uri:
    url: "{{ hadoop_download_url_checksum }}"
    return_content: true
  register: hadoop_download_checksum_raw

- name: "{{ hadoop_task_prefix }} Extract checksum"
  ansible.builtin.set_fact:
    hadoop_download_checksum: "{{ hadoop_download_checksum_raw.content.split(' = ')[1] }}"

- name: "{{ hadoop_task_prefix }} Download tarball"
  ansible.builtin.get_url:
    url: "{{ hadoop_download_url_file }}"
    dest: "{{ hadoop_path_tarball }}"
    checksum: "{{ hadoop_download_checksum_algo }}:{{ hadoop_download_checksum }}"

- name: "{{ hadoop_task_prefix }} Unpack tarball"
  ansible.builtin.unarchive:
    src: "{{ hadoop_path_tarball }}"
    dest: "{{ hadoop_path_base }}"
    remote_src: true
    creates: "{{ hadoop_path_unpacked }}"

- name: "{{ hadoop_task_prefix }} Copy binaries"
  ansible.builtin.copy:
    src: "{{ hadoop_path_unpacked }}"
    dest: "{{ hadoop_path_install }}"
    remote_src: true
    force: false

- name: "{{ hadoop_task_prefix }} Create data directory"
  file:
    path: "{{ hadoop_path_data }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'

- name: "{{ hadoop_task_prefix }} Template exclusion list"
  template:
    src: "{{ hadoop_template_exclusion_list }}"
    dest: "{{ hadoop_path_data }}/exclusion-list"
    owner: root
    group: root
    mode: '0644'
  #notify: hadoop_handler_refresh_nodes

- name: "{{ hadoop_task_prefix }} Template core-site.xml"
  template:
    src: "{{ hadoop_template_core_site_xml }}"
    dest: "{{ hadoop_path_config }}/core-site.xml"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Template hdfs-site.xml"
  template:
    src: "{{ hadoop_template_hdfs_site_xml }}"
    dest: "{{ hadoop_path_config }}/hdfs-site.xml"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Template hadoop-env.sh"
  template:
    src: "{{ hadoop_template_hadoop_env_sh }}"
    dest: "{{ hadoop_path_config }}/hadoop-env.sh"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Template yarn-env.sh"
  template:
    src: "{{ hadoop_template_yarn_env_sh }}"
    dest: "{{ hadoop_path_config }}/yarn-env.sh"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Template yarn-site.xml"
  template:
    src: "{{ hadoop_template_yarn_site_xml }}"
    dest: "{{ hadoop_path_config }}/yarn-site.xml"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Template mapred-site.xml"
  template:
    src: "{{ hadoop_template_mapred_site_xml }}"
    dest: "{{ hadoop_path_config }}/mapred-site.xml"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Create log directory"
  file:
    path: "{{ hadoop_path_log }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
    mode: '0775'

- name: "{{ hadoop_task_prefix }} Create journalnode directory"
  file:
    path: "{{ hadoop_path_data_journalnode }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'

- name: "{{ hadoop_task_prefix }} Install journalnode service unit"
  template:
    src: "{{ hadoop_template_journalnode_service }}"
    dest: "{{ hadoop_path_systemd_journalnode }}"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Start journalnode service"
  systemd:
    name: "{{ hadoop_systemd_journalnode_name }}"
    enabled: "{{ hadoop_systemd_journalnode_enabled | bool }}"
    masked: "{{ hadoop_systemd_journalnode_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_journalnode_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_journalnode_state }}"

- name: "{{ hadoop_task_prefix }} Create namenode directory"
  file:
    path: "{{ hadoop_path_data_namenode }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    recurse: true

- name: "{{ hadoop_task_prefix }} Check current subdir in namenode dir"
  stat:
    path: "{{ hadoop_path_data_namenode }}/current"
  register: hadoop_namenode_current

- name: "{{ hadoop_task_prefix }} Set formatted flag to false"
  set_fact:
    hadoop_namenode_formatted: false

- name: "{{ hadoop_task_prefix }} Check if namenode is formatted"
  set_fact:
    hadoop_namenode_formatted: "{{ hadoop_namenode_current.stat.isdir }}"
  when: hadoop_namenode_current.stat.isdir is defined

- name: "{{ hadoop_task_prefix }} Format first namenode"
  become: true
  become_user: "{{ hadoop_user }}"
  shell: "{{ hadoop_path_install }}/bin/hdfs namenode -format"
  when: not hadoop_namenode_formatted
  run_once: true

- name: "{{ hadoop_task_prefix }} Check current subdir in namenode dir"
  stat:
    path: "{{ hadoop_path_data_namenode }}/current"
  register: hadoop_namenode_current

- name: "{{ hadoop_task_prefix }} Set formatted flag to false"
  set_fact:
    hadoop_namenode_formatted: false

- name: "{{ hadoop_task_prefix }} Check if namenode is formatted"
  set_fact:
    hadoop_namenode_formatted: "{{ hadoop_namenode_current.stat.isdir }}"
  when: hadoop_namenode_current.stat.isdir is defined

- name: "{{ hadoop_task_prefix }} Install namenode service unit"
  template:
    src: "{{ hadoop_template_namenode_service }}"
    dest: "{{ hadoop_path_systemd_namenode }}"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Start first namenode"
  systemd:
    name: "{{ hadoop_systemd_namenode_name }}"
    enabled: "{{ hadoop_systemd_namenode_enabled | bool }}"
    masked: "{{ hadoop_systemd_namenode_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_namenode_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_namenode_state }}"
  when: hadoop_namenode_formatted

- name: "{{ hadoop_task_prefix }} Format remaining namenode"
  become: true
  become_user: "{{ hadoop_user }}"
  shell: "{{ hadoop_path_install }}/bin/hdfs namenode -bootstrapStandby -force"
  when: not hadoop_namenode_formatted

- name: "{{ hadoop_task_prefix }} Start remaining namenodes"
  systemd:
    name: "{{ hadoop_systemd_namenode_name }}"
    enabled: "{{ hadoop_systemd_namenode_enabled | bool }}"
    masked: "{{ hadoop_systemd_namenode_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_namenode_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_namenode_state }}"

- block:
    - name: "{{ hadoop_task_prefix }} Check if ZooKeeper is formatted"
      shell: "{{ hadoop_path_zkcli }} -server {{ backnet_ip }} ls /hadoop-ha/{{ hadoop_conf_nameservice_id }}"
      register: hadoop_zk_output
      ignore_errors: true
    
    - name: "{{ hadoop_task_prefix }} Format ZooKeeper"
      shell: "{{ hadoop_path_install }}/bin/hdfs zkfc -formatZK"
      when: "'does not exist' in hadoop_zk_output.stderr"
  run_once: true

- name: "{{ hadoop_task_prefix }} Install ZKFC service unit"
  template:
    src: "{{ hadoop_template_zkfc_service }}"
    dest: "{{ hadoop_path_systemd_zkfc }}"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Start ZKFC service"
  systemd:
    name: "{{ hadoop_systemd_zkfc_name }}"
    enabled: "{{ hadoop_systemd_zkfc_enabled | bool }}"
    masked: "{{ hadoop_systemd_zkfc_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_zkfc_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_zkfc_state }}"

- name: "{{ hadoop_task_prefix }} Create datanode directory"
  file:
    path: "{{ hadoop_path_data_datanode }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    recurse: true

- name: "{{ hadoop_task_prefix }} Install datanode service unit"
  template:
    src: "{{ hadoop_template_datanode_service }}"
    dest: "{{ hadoop_path_systemd_datanode }}"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Start datanode service"
  systemd:
    name: "{{ hadoop_systemd_datanode_name }}"
    enabled: "{{ hadoop_systemd_datanode_enabled | bool }}"
    masked: "{{ hadoop_systemd_datanode_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_datanode_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_datanode_state }}"

- name: "{{ hadoop_task_prefix }} Install Yarn resource manager service unit"
  template:
    src: "{{ hadoop_template_yarnrm_service }}"
    dest: "{{ hadoop_path_systemd_yarnrm }}"
    owner: root
    group: root
    mode: '0644'
  when: inventory_hostname == hadoop_host_yarn_resourcemanager

- name: "{{ hadoop_task_prefix }} Start Yarn resource manager service"
  systemd:
    name: "{{ hadoop_systemd_yarnrm_name }}"
    enabled: "{{ hadoop_systemd_yarnrm_enabled | bool }}"
    masked: "{{ hadoop_systemd_yarnrm_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_yarnrm_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_yarnrm_state }}"
  when: inventory_hostname == hadoop_host_yarn_resourcemanager

- name: "{{ hadoop_task_prefix }} Create Yarn NM log dir"
  ansible.builtin.file:
    path: "{{ hadoop_path_log_yarn }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'

- name: "{{ hadoop_task_prefix }} Install Yarn node manager service unit"
  template:
    src: "{{ hadoop_template_yarnnm_service }}"
    dest: "{{ hadoop_path_systemd_yarnnm }}"
    owner: root
    group: root
    mode: '0644'

- name: "{{ hadoop_task_prefix }} Start Yarn node manager service"
  systemd:
    name: "{{ hadoop_systemd_yarnnm_name }}"
    enabled: "{{ hadoop_systemd_yarnnm_enabled | bool }}"
    masked: "{{ hadoop_systemd_yarnnm_masked | bool }}"
    daemon_reload: "{{ hadoop_systemd_yarnnm_daemon_reload | bool }}"
    state: "{{ hadoop_systemd_yarnnm_state }}"
...
